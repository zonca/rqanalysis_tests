{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import time as t\n",
    "from array import array\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "RDataFrame = ROOT.RDataFrame\n",
    "DaskRDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame\n",
    "\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"\n",
    "    Setup connection to a Dask cluster. Two ingredients are needed:\n",
    "    1. Creating a cluster object that represents computing resources. This can be\n",
    "       done in various ways depending on the type of resources at disposal. To use\n",
    "       only the local machine (e.g. your laptop), a `LocalCluster` object can be\n",
    "       used. This step can be skipped if you have access to an existing Dask\n",
    "       cluster; in that case, the cluster administrator should provide you with a\n",
    "       URL to connect to the cluster in step 2. More options for cluster creation\n",
    "       can be found in the Dask docs at\n",
    "       http://distributed.dask.org/en/stable/api.html#cluster .\n",
    "    2. Creating a Dask client object that connects to the cluster. This accepts\n",
    "       directly the object previously created. In case the cluster was setup\n",
    "       externally, you need to provide an endpoint URL to the client, e.g.\n",
    "       'https://myscheduler.domain:8786'.\n",
    "\n",
    "    Through Dask, you can connect to various types of cluster resources. For\n",
    "    example, you can connect together a set of machines through SSH and use them\n",
    "    to run your computations. This is done through the `SSHCluster` class. For\n",
    "    example:\n",
    "\n",
    "    ```python\n",
    "    from dask.distributed import SSHCluster\n",
    "    cluster = SSHCluster(\n",
    "        # A list with machine host names, the first name will be used as\n",
    "        # scheduler, following names will become workers.\n",
    "        hosts=[\"machine1\",\"machine2\",\"machine3\"],\n",
    "        # A dictionary of options for each worker node, here we set the number\n",
    "        # of cores to be used on each node.\n",
    "        worker_options={\"nprocs\":4,},\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Another common usecase is interfacing Dask to a batch system like HTCondor or\n",
    "    Slurm. A separate package called dask-jobqueue (https://jobqueue.dask.org)\n",
    "    extends the available Dask cluster classes to enable running Dask computations\n",
    "    as batch jobs. In this case, the cluster object usually receives the parameters\n",
    "    that would be written in the job description file. For example:\n",
    "\n",
    "    ```python\n",
    "    from dask_jobqueue import HTCondorCluster\n",
    "    cluster = HTCondorCluster(\n",
    "        cores=1,\n",
    "        memory='2000MB',\n",
    "        disk='1000MB',\n",
    "    )\n",
    "    # Use the scale method to send as many jobs as needed\n",
    "    cluster.scale(4)\n",
    "    ```\n",
    "\n",
    "    In this tutorial, a cluster object is created for the local machine, using\n",
    "    multiprocessing (processes=True) on 2 workers (n_workers=2) each using only\n",
    "    1 core (threads_per_worker=1) and 2GiB of RAM (memory_limit=\"2GiB\").\n",
    "    \"\"\"\n",
    "    cluster = LocalCluster(n_workers=2, threads_per_worker=1, processes=True, memory_limit=\"4GiB\")\n",
    "    client = Client(cluster)\n",
    "    return client\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    connection = create_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #You can probably work with any one voltage, just comment out the others\n",
    "    series= {\"0V\":[\"23220420_160544\", \"23220420_173224\", \"23220420_213243\", \"23220421_013301\", \"23220421_053320\"],\n",
    "             \"20V\":[\"23220417_012632\",\"23220417_052651\",\"23220417_092710\",\"23220417_132730\",\"23220417_172749\",\"23220417_212807\",\"23220418_012825\",\"23220418_052843\",\n",
    "             \"23220418_092901\",\"23220418_132921\",\"23220418_172940\"],\n",
    "             \"50V\":[\"23220421_161919\",\"23220421_201938\",\"23220422_001957\",\"23220422_042016\",\"23220422_082034\",\"23220422_163644\",\"23220422_203703\",\"23220423_003722\",\n",
    "             \"23220423_043740\",\"23220423_083758\",\"23220423_123817\",\"23220423_163836\",\"23220423_203855\",\"23220424_003913\",\"23220424_043931\",\"23220424_083950\",\n",
    "             \"23220424_124008\",\"23220424_164027\",\"23220424_204045\",\"23220425_004105\",\"23220425_161451\",\"23220425_201511\",\"23220426_001529\",\"23220426_041547\",\n",
    "             \"23220426_081605\",\"23220426_181218\",\"23220426_221238\",\"23220427_021256\",\"23220427_061315\"]}\n",
    "    voltages={\"0V\",\"20V\",\"50V\"} #Comment out voltages you're not using\n",
    "\n",
    "    run_number = 24\n",
    "    detNo = [5]\n",
    "    detList={\"5\":\"S101\"}\n",
    "    chanList={\"S101\":[\"PBS2\",\"PFS2\",\"PAS2\",\"PT\"]}\n",
    "    chanHV={\"S101\":[\"PFS2\",\"PCS2\",\"PES2\",\"PT\"]}\n",
    "\n",
    "    #Loading data\n",
    "    # catalog = CDMSDataCatalog(default_fetchdir=\"/sdf/group/supercdms/data\")\n",
    "\n",
    "    ProdTag = \"S101Ba\"\n",
    "    base = \"/cvmfs/data/CDMS/RDataFrame_testing/data/s101/\"\n",
    "    file_list={}\n",
    "    for v in voltages:\n",
    "        fv=[]\n",
    "        for s in series[v]:\n",
    "            fv.append(f'{base}{ProdTag}_{s}.root')\n",
    "        file_list[v]=fv\n",
    "\n",
    "    fetchresult={}\n",
    "    for v in voltages:\n",
    "        print(\"Fetching {} files for \".format(len(file_list[v]))+v+\" ...\")\n",
    "    #     fetchresult[v] = catalog.fetch(file_list[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    files = file_list.values()\n",
    "    files = [x for xs in files for x in xs]\n",
    "    for i in files:\n",
    "        print(i)\n",
    "    #     !du -h {i}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    chains_zip5 = {}\n",
    "    chains_events = {}\n",
    "    for bias in file_list:\n",
    "        chains_zip5[bias] = ROOT.TChain()\n",
    "        chains_events[bias] = ROOT.TChain()\n",
    "        for file in file_list[bias]:\n",
    "            chains_zip5[bias].Add(f'{file}?#rqDir/zip5')\n",
    "            chains_events[bias].Add(f'{file}?#rqDir/eventTree')\n",
    "        chains_zip5[bias].AddFriend(chains_events[bias])\n",
    "    df = {}\n",
    "    for bias in file_list:\n",
    "        df[bias] = DaskRDataFrame(chains_zip5[bias], daskclient=connection)\n",
    "        # df[bias] = RDataFrame(chains_zip5[bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(df[bias].Count().GetValue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    ROOT.gInterpreter.Declare(\n",
    "    '''\n",
    "    bool cBaselineCut_0V(double PAS2bs) {\n",
    "        double mu_gaus=32770.21147818;\n",
    "        double sigma_gaus=85.51944755;\n",
    "        return (PAS2bs > mu_gaus-sigma_gaus)&&(PAS2bs < mu_gaus+1.5*sigma_gaus);\n",
    "    }\n",
    "    '''\n",
    "    )\n",
    "\n",
    "    ROOT.gInterpreter.Declare(\n",
    "    '''\n",
    "    bool cBaselineCut_20V(double PFS2bs) {\n",
    "        double mu_gaus=32437.83876944;\n",
    "        double sigma_gaus=50.79565417;\n",
    "        return (PFS2bs > mu_gaus-sigma_gaus) && (PFS2bs < mu_gaus+1.5*sigma_gaus);\n",
    "    }\n",
    "    '''\n",
    "    )\n",
    "    ROOT.gInterpreter.Declare(\n",
    "    '''\n",
    "    bool cBaselineCut_50V(double PAS2bs) {\n",
    "        double mu_gaus=32678.36298014;\n",
    "        double sigma_gaus=795.65838302;\n",
    "        return (PAS2bs > mu_gaus-sigma_gaus) && (PAS2bs < mu_gaus+1.5*sigma_gaus);\n",
    "    }\n",
    "    '''\n",
    "    )\n",
    "    ROOT.gInterpreter.Declare(\n",
    "    '''\n",
    "    bool cBasicCut(int TriggerType, int TriggerDetectorNum) {\n",
    "        return (TriggerType == 1) && (TriggerDetectorNum ==5);\n",
    "    }\n",
    "    '''\n",
    "    )\n",
    "\n",
    "    @ROOT.Numba.Declare([\"float\",\"float\"], \"bool\")\n",
    "    def cChisqCut_0V(PTOFchisq, PTOFamps):\n",
    "        amp=np.array([-999999,0,5e-7,1e-6,1.5e-6,2e-6,2.5e-6,3e-6,3.5e-6,4e-6,4.5e-6,5e-6,5.5e-6,6e-6,6.5e-6,7e-6,7.5e-6,8e-6,8.5e-6,9e-6])\n",
    "        chi=(np.array([-1e7,4e4,4e4,4e4,4.2e4,4.5e4,5e4,5.5e4,7e4,1e5,1.3e5,1.9e5,2.7e5,4e5,6e5,9e5,1.5e6,3e6,8e6,2.5e7]))\n",
    "        arc = np.interp(PTOFamps,amp, chi)\n",
    "        return (PTOFchisq < arc)\n",
    "    t.sleep(0.1)\n",
    "    @ROOT.Numba.Declare([\"float\",\"float\"], \"bool\")\n",
    "    def cChisqCut_20V(PTOFchisq, PTOFamps):\n",
    "        amp=np.array([-999999,0,5e-7,1e-6,1.5e-6,2e-6,2.5e-6,3e-6,3.5e-6,4e-6,4.5e-6,5e-6,5.5e-6,6e-6,6.5e-6,7e-6,7.5e-6,8e-6,8.5e-6])\n",
    "        chi=(np.array([-1e7,4e4,4e4,4e4,4.2e4,4.5e4,5e4,5.5e4,7e4,1e5,1.3e5,1.9e5,2.7e5,4e5,6e5,1e6,2.5e6,7e6,2e7])) \n",
    "        arc = np.interp(PTOFamps,amp, chi)\n",
    "        return (PTOFchisq < arc)\n",
    "\n",
    "    @ROOT.Numba.Declare([\"float\",\"float\"], \"bool\")\n",
    "    def cChisqCut_50V(PTOFchisq, PTOFamps):\n",
    "        amp=np.array([-999999,0,5e-7,1e-6,1.5e-6,2e-6,2.5e-6,\n",
    "                      3e-6,3.5e-6,4e-6,4.5e-6,5e-6,5.5e-6,6e-6,\n",
    "                      6.5e-6,7e-6,7.5e-6,8e-6,8.5e-6,9e-6,9.5e-6])\n",
    "        chi=(np.array([-1e7,3.9e4,3.9e4,3.9e4,4e4,4.2e4,4.5e4\n",
    "                       ,5e4,6e4,7.5e4,1e5,1.3e5,1.8e5,2.8e5,\n",
    "                       4e5,6.8e5,1.4e6,3e6,7e6,1.5e7,4e7]))\n",
    "        arc = np.interp(PTOFamps,amp, chi)\n",
    "        return (PTOFchisq < arc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    filterd_df = {}\n",
    "    for v in ['0V','20V','50V']:   \n",
    "        filterd_df[v] = df[v].Filter(f'Numba::cChisqCut_{v}(PTOFchisq, PTOFamps)')\\\n",
    "                             .Filter('cBasicCut(TriggerType, TriggerDetectorNum)')\\\n",
    "                             .Filter(f'cBaselineCut_{v}(PAS2bs)')\\\n",
    "                             .Define('Int_sum','PBS2INTall+PFS2INTall+PAS2INTall')\n",
    "    hists ={}\n",
    "    for v in ['0V','20V','50V']:\n",
    "        name = v\n",
    "        hist_signiture = name,name,200,0,0.045\n",
    "        hists[v] = filterd_df[v].Histo1D(hist_signiture,'Int_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(df[v].Filter('cBasicCut(TriggerType, TriggerDetectorNum)').Count().GetValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(df[v].Filter(f'Numba::cChisqCut_{v}(PTOFchisq, PTOFamps)').Count().GetValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(filterd_df[v].Count().GetValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    def TH2python(hist):\n",
    "        N = hist.GetNbinsX()\n",
    "        centers = np.array([hist.GetBinCenter(i) for i in range(N)])\n",
    "        values = np.array([hist.GetBinContent(i) for i in range(N)])\n",
    "        return (centers,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    fig,ax=plt.subplots()\n",
    "    for v in [\"0V\",\"20V\",\"50V\"]:\n",
    "        hist = hists[v].GetValue()\n",
    "        plt.step(*TH2python(hist),label=v+'root')\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.ylim(0,1e-2)\n",
    "    plt.xlabel(\"Integrated amplitude (a.u.)\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.grid(axis=\"both\",which='major')\n",
    "    #plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.title(r\"${}^{133}$Ba spectrum\")\n",
    "    plt.text(0.5, 0.5, 'SuperCDMS work in progress', transform=ax.transAxes,fontsize=30, color='gray', alpha=1,ha='center', va='center')\n",
    "    _ = plt.ylabel(\"Event rate (/ kg /day)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microroot",
   "language": "python",
   "name": "microroot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
